{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tick 3\n",
    "\n",
    "* [Pandas warmup exercises](#notes3) &mdash; not assessed\n",
    "* [Tick 3a](#tick3a) &mdash; worth 1 mark\n",
    "* [Tick 3b](#tick3b) &mdash; worth 1 mark\n",
    "* [Tick 3*](#tick3star) &mdash; not assessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas warmup exercises (not assessed)<span id=\"notes3\"></span>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    These are optional warmup exercises, to get you used to pandas. \n",
    "    </div>\n",
    "\n",
    "Use the following autograder settings:\n",
    "```\n",
    "import ucamcl\n",
    "GRADER = ucamcl.autograder('https://markmy.solutions', course='scicomp').subsection('notes3')\n",
    "```\n",
    "Each question has a label (in brackets). Call `fetch_question` to see a model answer.\n",
    "```\n",
    "q = GRADER.fetch_question('ex1')\n",
    "# view the answer\n",
    "print(q)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise (ex1)** from section 3.5. In pandas, to find the most frequent value (the _mode_)\n",
    "of `age_range` in the `stopsearch` dataset, we can use\n",
    "```\n",
    "stopsearch['age_range'].mode().values[0]\n",
    "```\n",
    "(The `mode()` call returns an object, and `.values[0]` extracts just the value itself.)\n",
    "\n",
    "How would you generate a table showing the most frequent age range for each combination of ethnicity and gender?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise (ex2)** from section 3.4 and 3.5. \n",
    "Given the dataframe\n",
    "```\n",
    "df = pandas.DataFrame({'A': [0,0,0,1,1,1], 'B': [0,1,2,0,1,2], 'X': range(6)})\n",
    "```\n",
    "how do you produce a table that has rows for A, columns for B, and shows values of X?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise (ex3)** from section 3.6. This code produces a dataframe with columns for ethnicity, outcome, and n:\n",
    "```\n",
    "sscam = stopsearch.loc[stopsearch.force=='cambridgeshire'].copy()\n",
    "sscam['outcome'] = np.where(sscam.outcome == 'False', 'nothing', 'find')\n",
    "df = sscam.groupby(['officer_defined_ethnicity','outcome']).apply(len).reset_index(name='n')\n",
    "```\n",
    "Take the subtable with `outcome=='nothing'`, and the subtable with `outcome='find'`, and merge them; then use the merged table to compute the\n",
    "`percent_find` column from section 3.6 of notes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise (ex4)** from section 3.5. As an alternative to the method in exercise ex3, \n",
    "take the indexed array\n",
    "```\n",
    "sscam.groupby(['officer_defined_ethnicity','outcome']).apply(len)\n",
    "```\n",
    "and convert it to a wide-form dataframe, then use this to compute `percent_find`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tick 3a. Analysis of flood data<span id=\"tick3a\"></span>\n",
    "\n",
    "This section is worth 1 mark. Use these autograder settings:\n",
    "```\n",
    "import ucamcl\n",
    "GRADER = ucamcl.autograder('https://markmy.solutions', course='scicomp').subsection('tick3a')\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "This assignment tests your skill at manipulating dataframes and indexed arrays.\n",
    "    <strong>YOUR CODE MUST USE PANDAS AND NUMPY OPERATIONS FOR DATA MANIPULATION</strong>\n",
    "    rather than for loops, wherever possible.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "![Jesus Green lock](res/jesus_green_lock.jpg)\n",
    "\n",
    "This assignment asks you to analyse data provided by the UK Environment Agency concerning flooding. The agency offers an [API for near real-time data](http://environment.data.gov.uk/flood-monitoring/doc/reference) covering:\n",
    "* flood warnings and flood alerts\n",
    "* flood areas which to which warnings or alerts apply\n",
    "* measurements of water levels and flows\n",
    "* information on the monitoring stations providing those measurements\n",
    "\n",
    "In this assignment we will be working with historical data of water level measurements, at several monitoring stations in Cambridge and on the Cam. The dataset is available as a CSV file at [https://teachingfiles.blob.core.windows.net/datasets/flood_20191125.csv](https://teachingfiles.blob.core.windows.net/datasets/flood_20191125.csv).\n",
    "\n",
    "_Image by [N. Chadwick](http://www.geograph.org.uk/photo/4800494)._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** Import the CSV file and print out a few lines, choosing the lines at random using `np.random.choice`. The file mistakenly includes records from a River Cam in Gloucestershire, and another River Cam in Somerset. Remove these rows, and store what's left as the data frame `flood`. How many rows are left?\n",
    "```\n",
    "# Submit your answer:\n",
    "GRADER.submit_answer(GRADER.fetch_question('q1'), num_rows)\n",
    "```\n",
    "\n",
    "_Hint. [`DataFrame.drop_duplicates`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop_duplicates.html) may be useful for seeing what's in the file._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** Complete this table of the number of entries in this dataset for each town and river.\n",
    "\n",
    "| . | Cambridge | Great Chesterford | Great Shelford | Milton |\n",
    "| -- |||||\n",
    "| **Bin Brook** | 2628 | 0 |||\n",
    "| **River Cam** |||||\n",
    "\n",
    "```\n",
    "# Submit your answer\n",
    "your_ans = ...  # an unstacked indexed array\n",
    "GRADER.submit_answer(GRADER.fetch_question('q2'), your_ans.values)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.** Each water measuring station has a distinct `measure_id` and `label`. Complete this dataframe of the number of measurement stations for each town and river. Use only the Pandas operations for split-apply-combine, don't use any numpy operations or Python `for` loops or list comprehensions. \n",
    "\n",
    "| town | num_stations |\n",
    "|--||\n",
    "| Milton | 1 |\n",
    "| Great Shelford | 1 |\n",
    "\n",
    "```\n",
    "# Submit your answer. Row order doesn't matter.\n",
    "GRADER.submit_answer(GRADER.fetch_question('q3'), your_dataframe)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** \n",
    "Each measurement station has low and high reference levels, in columns `low` and `high`. In this dataset, the reference levels are stored for every measurement, but we can verify that every `measure_id` has a unique pair `(low,high)` with\n",
    "```\n",
    "assert all(flood.groupby(['measure_id','low','high']).apply(len).groupby('measure_id').apply(len) == 1), \"Reference levels non-constant\"\n",
    "```\n",
    "Add a column `norm_value`, by rescaling `value` linearly so that `value=low` correponds to `norm_value=0` and `value=high` corresponds to `norm_value=1`.\n",
    "Use `np.nanquantile` to find the [_tercile points_](https://en.wiktionary.org/wiki/tercile), the two values that split the entire `norm_value` column into three roughly equal parts.\n",
    "\n",
    "```\n",
    "# Submit your answer:\n",
    "GRADER.submit_answer(GRADER.fetch_question('q4'), [tercile1, tercile2])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.** Complete the following dataframe, listing the number of observations in each tercile and the total. (When there are repeated values, it's arbitrary how we assign observations into terciles. To answer this question, use the convention that `med` means `tercile1 <= value < tercile2`.)\n",
    "\n",
    "| label | norm_value_tercile | n | ntot |\n",
    "|--||||\n",
    "| Bin Brook | med | 2466 | 2628 |\n",
    "| Bin Brook | high | 162 | 2628 |\n",
    "| Cambridge Baits Bite | low | 2 | 2813 |\n",
    "\n",
    "```\n",
    "# Submit your answer. Row order doesn't matter.\n",
    "GRADER.submit_answer(GRADER.fetch_question('q5'), your_dataframe)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6.** Complete this dataframe, listing the fraction of observations in each tercile per station:\n",
    "\n",
    "| label | low | med | high |\n",
    "|---- ||||\n",
    "| Bin Brook | 0.000 | 0.938 | 0.062 |\n",
    "| Cambridge Jesus Lock | 0.032 | 0.356 | 0.612 |\n",
    "\n",
    "```\n",
    "# Submit your answer. Row order doesn't matter. Don't round.\n",
    "GRADER.submit_answer(GRADER.fetch_question('q6'), your_dataframe)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7.** Fill in the rest of this indexed array, giving the `low` and `high` values for each measurement station.\n",
    "\n",
    "| label | ref | |\n",
    "|----|||\n",
    "| Bin Brook | high | 1.000 |\n",
    "| | low | 0.057 |\n",
    "| Cambridge Baits Bite | high | 0.294 |\n",
    "| | low | 0.218 |\n",
    "\n",
    "```\n",
    "# Submit your answer. Let your_ans be an indexed array.\n",
    "GRADER.submit_answer(GRADER.fetch_question('q7'), your_ans.reset_index(name='val'))\n",
    "```\n",
    " _Hint. There are many ways to approach this. The cleanest is to use [`melt`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.melt.html#pandas.DataFrame.melt)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tick 3b. Plotting\n",
    "\n",
    "This section is worth 1 mark. There is no automated testing of your answers here, but your code may be assessed in the ticking session.\n",
    "\n",
    "<div class=\"alert alert-warning\">For this assignment you will need\n",
    "    to figure out matplotlib's myriad options.\n",
    "    You will need to spend time <a href=\"https://stackoverflow.com/questions/tagged/matplotlib\">searching</a> for help.  \n",
    "    You don't need to be pixel perfect, but you do need to demonstrate that you can control\n",
    "    <ul>\n",
    "        <li>aspect ratio</li>\n",
    "        <li>subplots layout and spacing</li>\n",
    "        <li>x and y axis ranges, and colour palette</li>\n",
    "        <li>display of tick labels and gridlines</li>\n",
    "        <li>legend placement</li>\n",
    "        <li>titles</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8.** Reproduce this plot:\n",
    "\n",
    "<img src=\"res/tick3b_bar.svg\" style=\"height:22em\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9.** Reproduce this plot:\n",
    "\n",
    "<img src=\"res/tick3b_timeseries.svg\" style=\"height:30em\"/>\n",
    "\n",
    "\n",
    "The light shaded area shows the range from `low` to `high` for each station. The dark shaded area shows the inter-tercile range, `low+tercile1*(high-low)` to `low+tercile2*(high-low)` where `tercile1` and `tercile2` are your answers to Question 4. They can be plotted with [`ax.axhspan`](https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.axhspan.html#matplotlib.axes.Axes.axhspan).\n",
    "Here are some code snippets that may be useful, for formatting tick labels with dates.\n",
    "```\n",
    "import matplotlib\n",
    "# Date-axis control, taken from http://matplotlib.org/examples/api/date_demo.html\n",
    "ax.xaxis.set_major_locator(matplotlib.dates.WeekdayLocator(byweekday=matplotlib.dates.MO, tz=pytz.UTC))\n",
    "ax.xaxis.set_minor_locator(matplotlib.dates.DayLocator(tz=pytz.UTC))\n",
    "ax.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%a %d %b'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tick 3* (not assessed)<span id=\"tick3star\"></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 10.** The real story in this dataset is about the [Yorkshire floods of 2019](https://en.wikipedia.org/wiki/2019_Yorkshire_floods). Using the full dataset of all readings, \n",
    "plot a map showing the peak water level at each measuring station. Here's an illustration.\n",
    "\n",
    "<img src=\"res/tick3star_flooding.svg\" style=\"height:20em\"/>\n",
    "\n",
    "You can download the full dataset in three files,\n",
    "\n",
    "* https://teachingfiles.blob.core.windows.net/datasets/stations_20191125.csv\n",
    "* https://teachingfiles.blob.core.windows.net/datasets/measures_20191125.csv\n",
    "* https://teachingfiles.blob.core.windows.net/datasets/readings_20191125.csv\n",
    "\n",
    "You will have to merge these files: `readings.measure_id` refers to `measures.measure_id`, and `measures.station_uri` refers to `station.uri`. You will also have to filter the readings, and only keep those with `parameter=='Water Level'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11.** The dataset also includes rainfall measurements. Plot rainfall and water level, for the worst-affected rivers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
